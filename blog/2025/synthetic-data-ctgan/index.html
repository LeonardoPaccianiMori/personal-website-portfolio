<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Why I Built a Custom Synthetic Data Algorithm Instead of Using CTGAN | Pinco Pallino </title> <meta name="author" content="Pinco Pallino"> <meta name="description" content="When off-the-shelf ML isn't enough—designing a KNN-based synthetic data generator that preserves feature correlations"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A8%F0%9F%8F%BB%E2%80%8D%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://unique-cocada-065d88.netlify.app//blog/2025/synthetic-data-ctgan/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Pinco</span> Pallino </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Why I Built a Custom Synthetic Data Algorithm Instead of Using CTGAN</h1> <p class="post-meta"> Created on May 15, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> machine-learning</a>   <a href="/blog/tag/synthetic-data"> <i class="fa-solid fa-hashtag fa-sm"></i> synthetic-data</a>   <a href="/blog/tag/algorithms"> <i class="fa-solid fa-hashtag fa-sm"></i> algorithms</a>   ·   <a href="/blog/category/data-science"> <i class="fa-solid fa-tag fa-sm"></i> data-science</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="the-problem-1-million-synthetic-real-estate-listings">The Problem: 1 Million Synthetic Real Estate Listings</h2> <p>For my <a href="/projects/italian-real-estate/">Italian Real Estate Analysis project</a>, I needed to generate synthetic data. A lot of it.</p> <p><strong>The requirements:</strong></p> <ul> <li>Create ~1 million synthetic property listings</li> <li>Preserve statistical distributions from real data</li> <li> <strong>Maintain critical feature correlations</strong> (especially location ↔ price)</li> <li>Ensure geographic coherence (coordinates within Italy’s borders)</li> <li>Support multiple property types, energy classes, and features</li> </ul> <p><strong>Why synthetic data?</strong> Two reasons:</p> <ol> <li> <strong>Privacy</strong>: Don’t publish exact real property data scraped from websites</li> <li> <strong>Augmentation</strong>: Increase dataset size for better ML training</li> </ol> <p>The obvious solution? Use <a href="https://github.com/sdv-dev/CTGAN" rel="external nofollow noopener" target="_blank">CTGAN</a>, a state-of-the-art generative AI model designed specifically for tabular data. It’s based on GANs (Generative Adversarial Networks) and has been shown to work well for generating realistic synthetic datasets.</p> <p><strong>Spoiler:</strong> CTGAN failed spectacularly for my use case. Here’s why, and how I built something better.</p> <hr> <h2 id="attempt-1-ctgan-the-obvious-solution">Attempt #1: CTGAN (The “Obvious” Solution)</h2> <p>CTGAN seemed perfect on paper:</p> <p>✅ <strong>Purpose-built for tabular data</strong> (unlike image-focused GANs) ✅ <strong>Handles mixed data types</strong> (categorical + continuous features) ✅ <strong>Preserves distributions</strong> well in benchmarks ✅ <strong>Actively maintained</strong> by the Synthetic Data Vault team ✅ <strong>Easy to use</strong> with a simple Python API</p> <h3 id="the-implementation">The Implementation</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">ctgan</span> <span class="kn">import</span> <span class="n">CTGAN</span>

<span class="c1"># Load real real estate data
</span><span class="n">real_data</span> <span class="o">=</span> <span class="nf">load_rental_listings</span><span class="p">()</span>  <span class="c1"># ~80,000 listings
</span>
<span class="c1"># Train CTGAN
</span><span class="n">ctgan</span> <span class="o">=</span> <span class="nc">CTGAN</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">ctgan</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">real_data</span><span class="p">,</span> <span class="n">discrete_columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">property_type</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">energy_class</span><span class="sh">'</span><span class="p">,</span> <span class="p">...])</span>

<span class="c1"># Generate synthetic data
</span><span class="n">synthetic_data</span> <span class="o">=</span> <span class="n">ctgan</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1_000_000</span><span class="p">)</span>
</code></pre></div></div> <p>Simple, right?</p> <h3 id="the-results-beautiful-distributions-broken-correlations">The Results: Beautiful Distributions, Broken Correlations</h3> <p>After training for several hours, CTGAN produced synthetic data with:</p> <p>✅ <strong>Price distribution</strong>: Nearly identical to real data ✅ <strong>Surface area distribution</strong>: Spot on ✅ <strong>Geographic distribution</strong>: Covered Italy properly ✅ <strong>Categorical features</strong>: Realistic proportions</p> <p><strong>But there was a critical problem:</strong></p> <p>❌ <strong>Location ↔ Price correlation was destroyed</strong></p> <p>In the real data:</p> <ul> <li>Properties in Milan (expensive city) → High prices</li> <li>Properties in rural areas → Low prices</li> <li>Coastal properties → Premium pricing</li> <li>Northern cities → Generally more expensive than southern</li> </ul> <p>In CTGAN’s synthetic data:</p> <ul> <li>Milan apartments priced like rural farmhouses</li> <li>Tiny studios in Rome costing more than villas in Tuscany</li> <li><strong>Complete randomness between location and price</strong></li> </ul> <h3 id="why-this-matters">Why This Matters</h3> <p>For my ML model (predicting rental prices), location is <strong>the most important feature</strong>. If synthetic data breaks the location-price relationship, it’s worthless for training.</p> <p><strong>Validation check I ran:</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Real data: R² between (lat, lon) and price
</span><span class="n">real_r2</span> <span class="o">=</span> <span class="nf">measure_location_price_correlation</span><span class="p">(</span><span class="n">real_data</span><span class="p">)</span>  <span class="c1"># 0.62
</span>
<span class="c1"># CTGAN synthetic data
</span><span class="n">ctgan_r2</span> <span class="o">=</span> <span class="nf">measure_location_price_correlation</span><span class="p">(</span><span class="n">synthetic_data</span><span class="p">)</span>  <span class="c1"># 0.03
</span></code></pre></div></div> <p>The geographic-price relationship was <strong>obliterated</strong>.</p> <hr> <h2 id="why-ctgan-failed-the-architecture-limitation">Why CTGAN Failed: The Architecture Limitation</h2> <p>CTGAN is brilliant at learning <strong>marginal distributions</strong> (how individual features are distributed), but struggles with <strong>complex multivariate relationships</strong>.</p> <h3 id="how-ctgan-works-simplified">How CTGAN Works (Simplified)</h3> <ol> <li> <strong>Generator</strong>: Creates fake rows</li> <li> <strong>Discriminator</strong>: Tries to spot fakes</li> <li> <strong>Training</strong>: Generator gets better at fooling discriminator</li> <li> <strong>Conditional generation</strong>: Uses class labels to guide generation</li> </ol> <p><strong>The problem:</strong> With 50+ features and complex geographic relationships, CTGAN couldn’t maintain the intricate correlations between:</p> <ul> <li>Latitude ↔ Price</li> <li>Longitude ↔ Price</li> <li>(Lat, Lon) ↔ Property Type</li> <li>(Lat, Lon) ↔ Energy Class</li> <li>And dozens of other location-dependent patterns</li> </ul> <p>It learned “Milan exists” and “expensive properties exist,” but not “Milan properties ARE expensive.”</p> <hr> <h2 id="the-solution-custom-k-nearest-neighbors-algorithm">The Solution: Custom K-Nearest Neighbors Algorithm</h2> <p>I needed an approach that <strong>preserves correlations by design</strong>, not by hoping a neural network learns them.</p> <h3 id="the-core-insight">The Core Insight</h3> <p>Instead of training a model to learn correlations, <strong>find similar real examples and blend them</strong>.</p> <p><strong>Algorithm concept:</strong></p> <ol> <li>For each synthetic listing to generate: <ul> <li>Find K=5 <strong>similar real listings</strong> (based on location, price, size)</li> <li>Weight them by similarity (closer = higher weight)</li> <li>Create synthetic listing by <strong>blending</strong> their features</li> </ul> </li> <li>Repeat 1 million times</li> </ol> <p><strong>Why this works:</strong> If you blend 5 real Milan apartments, you get a realistic synthetic Milan apartment. The location-price correlation is <strong>preserved by construction</strong>.</p> <hr> <h2 id="implementation-details">Implementation Details</h2> <h3 id="distance-metric">Distance Metric</h3> <p>I used a weighted Euclidean distance across 4 key features:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_distance</span><span class="p">(</span><span class="n">synthetic_point</span><span class="p">,</span> <span class="n">real_data</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Calculate weighted distance between synthetic point and all real listings
    </span><span class="sh">"""</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">surface</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">latitude</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">longitude</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.25</span>
    <span class="p">}</span>

    <span class="c1"># Normalize features to [0, 1] scale
</span>    <span class="n">normalized_real</span> <span class="o">=</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">real_data</span><span class="p">[</span><span class="nf">list</span><span class="p">(</span><span class="n">weights</span><span class="p">.</span><span class="nf">keys</span><span class="p">())])</span>
    <span class="n">normalized_synthetic</span> <span class="o">=</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">synthetic_point</span><span class="p">[</span><span class="nf">list</span><span class="p">(</span><span class="n">weights</span><span class="p">.</span><span class="nf">keys</span><span class="p">())])</span>

    <span class="c1"># Weighted Euclidean distance
</span>    <span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span>
        <span class="p">((</span><span class="n">normalized_real</span> <span class="o">-</span> <span class="n">normalized_synthetic</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="nf">list</span><span class="p">(</span><span class="n">weights</span><span class="p">.</span><span class="nf">values</span><span class="p">())).</span><span class="nf">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">distances</span>
</code></pre></div></div> <p><strong>Why these 4 features?</strong></p> <ul> <li> <strong>Price + Surface</strong>: Define the property’s market segment</li> <li> <strong>Lat + Lon</strong>: Define geographic location and context</li> <li>Together, they capture the most critical correlations</li> </ul> <h3 id="feature-blending-strategy">Feature Blending Strategy</h3> <p>For each feature type, different blending approach:</p> <p><strong>Numerical features</strong> (price, surface, rooms, etc.):</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Weighted average using inverse distance weights
</span><span class="n">weights</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">distances</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>  <span class="c1"># Avoid division by zero
</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">/</span> <span class="n">weights</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span>    <span class="c1"># Normalize to sum to 1
</span>
<span class="n">synthetic_price</span> <span class="o">=</span> <span class="p">(</span><span class="n">real_prices</span> <span class="o">*</span> <span class="n">weights</span><span class="p">).</span><span class="nf">sum</span><span class="p">()</span>
</code></pre></div></div> <p><strong>Categorical features</strong> (property_type, energy_class, etc.):</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Weighted voting: most common value among neighbors
</span><span class="n">votes</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">neighbor_idx</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">neighbor_indices</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="n">category</span> <span class="o">=</span> <span class="n">real_data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">neighbor_idx</span><span class="p">][</span><span class="sh">'</span><span class="s">property_type</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">votes</span><span class="p">[</span><span class="n">category</span><span class="p">]</span> <span class="o">=</span> <span class="n">votes</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">weight</span>

<span class="n">synthetic_property_type</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">votes</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">votes</span><span class="p">.</span><span class="n">get</span><span class="p">)</span>
</code></pre></div></div> <p><strong>Boolean features</strong> (elevator, balcony, terrace, etc.):</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Probabilistic: weighted average treated as probability
</span><span class="n">prob_has_elevator</span> <span class="o">=</span> <span class="p">(</span><span class="n">neighbor_elevator_values</span> <span class="o">*</span> <span class="n">weights</span><span class="p">).</span><span class="nf">sum</span><span class="p">()</span>
<span class="n">synthetic_has_elevator</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">prob_has_elevator</span><span class="p">)</span>
</code></pre></div></div> <h3 id="gpu-acceleration">GPU Acceleration</h3> <p>Computing distances for 1M synthetic points against 80K real points is <strong>expensive</strong>: 80 billion distance calculations.</p> <p><strong>CPU implementation</strong>: ~6 hours <strong>GPU implementation (TensorFlow)</strong>: ~36 minutes</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="k">def</span> <span class="nf">compute_distances_gpu</span><span class="p">(</span><span class="n">synthetic_batch</span><span class="p">,</span> <span class="n">real_data_tensor</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Vectorized distance computation on GPU
    </span><span class="sh">"""</span>
    <span class="c1"># Expand dimensions for broadcasting
</span>    <span class="n">synthetic_expanded</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">synthetic_batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch, 1, features]
</span>    <span class="n">real_expanded</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">real_data_tensor</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>      <span class="c1"># [1, n_real, features]
</span>
    <span class="c1"># Compute all pairwise distances at once
</span>    <span class="n">diff</span> <span class="o">=</span> <span class="n">synthetic_expanded</span> <span class="o">-</span> <span class="n">real_expanded</span>                <span class="c1"># [batch, n_real, features]
</span>    <span class="n">weighted_diff</span> <span class="o">=</span> <span class="n">diff</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">weights</span>                      <span class="c1"># Apply feature weights
</span>    <span class="n">distances</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">reduce_sum</span><span class="p">(</span><span class="n">weighted_diff</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>  <span class="c1"># [batch, n_real]
</span>
    <span class="k">return</span> <span class="n">distances</span>
</code></pre></div></div> <p><strong>Batch processing:</strong> Generate 1000 synthetic listings at a time to maximize GPU utilization without running out of memory.</p> <hr> <h2 id="results-validation">Results: Validation</h2> <h3 id="correlation-preservation">Correlation Preservation</h3> <table> <thead> <tr> <th><strong>Metric</strong></th> <th><strong>Real Data</strong></th> <th><strong>CTGAN</strong></th> <th><strong>Custom KNN</strong></th> </tr> </thead> <tbody> <tr> <td>Location ↔ Price R²</td> <td>0.62</td> <td>0.03</td> <td>0.58</td> </tr> <tr> <td>Surface ↔ Price R²</td> <td>0.71</td> <td>0.69</td> <td>0.70</td> </tr> <tr> <td>Milan price premium</td> <td>+45%</td> <td>+2%</td> <td>+42%</td> </tr> </tbody> </table> <p><strong>Result:</strong> Custom KNN preserves critical correlations while CTGAN destroys them.</p> <h3 id="distribution-quality">Distribution Quality</h3> <p>Both approaches produced good marginal distributions:</p> <ul> <li> <strong>Price</strong>: Realistic right-skewed distribution</li> <li> <strong>Surface area</strong>: Matches real data</li> <li> <strong>Geographic spread</strong>: Covers all Italian provinces</li> <li> <strong>Property type proportions</strong>: Realistic mix</li> </ul> <h3 id="geographic-coherence">Geographic Coherence</h3> <p><strong>CTGAN occasionally generated:</strong></p> <ul> <li>Properties in the Mediterranean Sea</li> <li>Coordinates outside Italy’s borders</li> <li>Impossible lat/lon combinations</li> </ul> <p><strong>Custom KNN:</strong></p> <ul> <li>✅ All coordinates within Italy (guaranteed by design)</li> <li>✅ Properties cluster in cities (like real data)</li> <li>✅ Rural properties in rural areas, urban in urban areas</li> </ul> <hr> <h2 id="performance-comparison">Performance Comparison</h2> <table> <thead> <tr> <th><strong>Aspect</strong></th> <th><strong>CTGAN</strong></th> <th><strong>Custom KNN</strong></th> </tr> </thead> <tbody> <tr> <td><strong>Training time</strong></td> <td>4-6 hours (GPU)</td> <td>N/A (no training)</td> </tr> <tr> <td><strong>Generation time</strong></td> <td>~2 minutes (1M samples)</td> <td>~36 minutes (1M samples, GPU)</td> </tr> <tr> <td><strong>Memory usage</strong></td> <td>Moderate</td> <td>High (distance matrices)</td> </tr> <tr> <td><strong>Correlation preservation</strong></td> <td>❌ Poor</td> <td>✅ Excellent</td> </tr> <tr> <td><strong>Scalability</strong></td> <td>Good (once trained)</td> <td>Moderate (needs real data access)</td> </tr> <tr> <td><strong>Code complexity</strong></td> <td>Low (library)</td> <td>Medium (custom implementation)</td> </tr> </tbody> </table> <hr> <h2 id="code-example-full-pipeline">Code Example: Full Pipeline</h2> <details> <summary><strong>Click to expand: Complete implementation</strong></summary> ```python import numpy as np import pandas as pd import tensorflow as tf from sklearn.preprocessing import MinMaxScaler class SyntheticDataGenerator: def __init__(self, real_data, k_neighbors=5): self.real_data = real_data self.k = k_neighbors self.scaler = MinMaxScaler() # Prepare normalized real data for distance computation self.feature_cols = ['price', 'surface', 'latitude', 'longitude'] self.normalized_real = self.scaler.fit_transform( real_data[self.feature_cols] ) def generate(self, n_synthetic, batch_size=1000): """Generate n synthetic listings""" synthetic_data = [] for batch_start in range(0, n_synthetic, batch_size): batch_size_actual = min(batch_size, n_synthetic - batch_start) # Sample anchor points from real data anchor_indices = np.random.choice( len(self.real_data), size=batch_size_actual, replace=True ) anchors = self.normalized_real[anchor_indices] # Add small random noise to anchors noise = np.random.normal(0, 0.05, anchors.shape) synthetic_points = np.clip(anchors + noise, 0, 1) # Find K nearest neighbors for each synthetic point distances = self.compute_distances_gpu( tf.constant(synthetic_points, dtype=tf.float32) ) # Get K nearest neighbor indices _, neighbor_indices = tf.nn.top_k( -distances, # Negative because top_k returns largest k=self.k ) neighbor_indices = neighbor_indices.numpy() # Blend features from neighbors batch_synthetic = self.blend_features( synthetic_points, neighbor_indices, distances.numpy() ) synthetic_data.append(batch_synthetic) if (batch_start // batch_size + 1) % 10 == 0: print(f"Generated {batch_start + batch_size_actual}/{n_synthetic} listings") return pd.concat(synthetic_data, ignore_index=True) def compute_distances_gpu(self, synthetic_batch): """Vectorized GPU distance computation""" # Convert to TensorFlow tensors real_tensor = tf.constant(self.normalized_real, dtype=tf.float32) # Broadcasting for pairwise distances synthetic_expanded = tf.expand_dims(synthetic_batch, 1) real_expanded = tf.expand_dims(real_tensor, 0) # Weighted Euclidean distance diff_squared = (synthetic_expanded - real_expanded) ** 2 distances = tf.sqrt(tf.reduce_sum(diff_squared, axis=2)) return distances def blend_features(self, synthetic_points, neighbor_indices, distances): """Blend features from neighbors""" synthetic_rows = [] for i, neighbors in enumerate(neighbor_indices): # Get neighbor data neighbor_data = self.real_data.iloc[neighbors] # Compute weights (inverse distance) neighbor_distances = distances[i, neighbors] weights = 1 / (neighbor_distances + 1e-6) weights = weights / weights.sum() # Blend features synthetic_row = {} # Numerical features: weighted average for col in ['price', 'surface', 'rooms', 'bathrooms', ...]: if col in neighbor_data.columns: synthetic_row[col] = (neighbor_data[col] * weights).sum() # Categorical features: weighted voting for col in ['property_type', 'energy_class', 'heating_type', ...]: if col in neighbor_data.columns: votes = {} for j, weight in enumerate(weights): value = neighbor_data.iloc[j][col] votes[value] = votes.get(value, 0) + weight synthetic_row[col] = max(votes, key=votes.get) # Boolean features: probabilistic for col in ['elevator', 'balcony', 'terrace', ...]: if col in neighbor_data.columns: prob = (neighbor_data[col].astype(float) * weights).sum() synthetic_row[col] = np.random.binomial(1, prob) synthetic_rows.append(synthetic_row) return pd.DataFrame(synthetic_rows) # Usage generator = SyntheticDataGenerator(real_rental_data, k_neighbors=5) synthetic_data = generator.generate(n_synthetic=1_000_000, batch_size=1000) ``` </details> <hr> <h2 id="lessons-learned">Lessons Learned</h2> <h3 id="1-off-the-shelf-isnt-always-best">1. Off-the-Shelf Isn’t Always Best</h3> <p>CTGAN is a sophisticated, well-engineered library. But for my specific use case (geographic data with strong location correlations), it wasn’t the right tool.</p> <p><strong>When to use CTGAN:</strong></p> <ul> <li>Features are mostly independent</li> <li>You need perfect marginal distributions</li> <li>You have lots of training data</li> <li>Correlations are simple/linear</li> </ul> <p><strong>When to build custom:</strong></p> <ul> <li>Domain-specific correlations are critical</li> <li>You understand the feature relationships</li> <li>You need guaranteed properties (e.g., geographic coherence)</li> <li>You have clear validation criteria</li> </ul> <h3 id="2-sometimes-simpler-is-better">2. Sometimes Simpler Is Better</h3> <p>My KNN approach is conceptually simpler than CTGAN (no neural networks, no adversarial training), yet it worked better for this problem.</p> <p><strong>Why?</strong> Because it exploits <strong>domain knowledge</strong>: “Similar properties should be geographically close.” CTGAN had to learn this from scratch, and failed.</p> <h3 id="3-validation-is-everything">3. Validation Is Everything</h3> <p>Without rigorous validation (correlation checks, geographic coherence, distribution comparisons), I might have shipped CTGAN-generated data and wondered why my ML model performed poorly.</p> <p><strong>Validation saved me from:</strong></p> <ul> <li>Training a price prediction model on nonsense data</li> <li>Wasting weeks debugging model architecture</li> <li>Producing a broken final product</li> </ul> <h3 id="4-gpu-acceleration-makes-custom-solutions-viable">4. GPU Acceleration Makes Custom Solutions Viable</h3> <p>Without GPU acceleration, my KNN approach would take ~6 hours (vs. CTGAN’s 2 minutes for generation). That’s a dealbreaker.</p> <p>With GPU: ~36 minutes. Totally acceptable for a one-time data generation task.</p> <p><strong>Takeaway:</strong> Don’t dismiss custom algorithms because they seem slow. Profile first, then optimize with GPU/vectorization.</p> <hr> <h2 id="when-would-i-use-ctgan">When Would I Use CTGAN?</h2> <p>Despite failing here, CTGAN is still a powerful tool. I’d use it for:</p> <ol> <li> <strong>Financial/transaction data</strong> (less geographic dependency)</li> <li> <strong>Medical records</strong> (need differential privacy guarantees, which CTGAN supports)</li> <li> <strong>Customer demographics</strong> (simpler correlations)</li> <li> <strong>Exploratory analysis</strong> (quick synthetic data for testing pipelines)</li> </ol> <p>But for <strong>geospatial data</strong> or datasets with <strong>known, strong correlations</strong>, custom approaches can work better.</p> <hr> <h2 id="code--resources">Code &amp; Resources</h2> <p>Full implementation available in my <a href="https://github.com/LeonardoPaccianiMori/italian-real-estate-pipeline" rel="external nofollow noopener" target="_blank">Italian Real Estate Pipeline repository</a> (see <code class="language-plaintext highlighter-rouge">notebooks/synthetic_data_generation.ipynb</code>).</p> <p><strong>Related reading:</strong></p> <ul> <li> <a href="https://arxiv.org/abs/1907.00503" rel="external nofollow noopener" target="_blank">CTGAN Paper</a> - Original research</li> <li> <a href="https://sdv.dev/SDV/" rel="external nofollow noopener" target="_blank">SDV Documentation</a> - Synthetic Data Vault library</li> <li> <a href="/projects/italian-real-estate/">My Real Estate Project</a> - Full pipeline context</li> </ul> <hr> <h2 id="key-takeaways">Key Takeaways</h2> <ol> <li> <strong>Validate synthetic data rigorously</strong> - Check correlations, not just distributions</li> <li> <strong>Domain knowledge &gt; Generic algorithms</strong> - When you know critical relationships, encode them directly</li> <li> <strong>GPU acceleration unlocks custom solutions</strong> - 10× speedups make “slow” algorithms viable</li> <li> <strong>Off-the-shelf tools are great starting points</strong> - But don’t be afraid to build custom when needed</li> <li> <strong>Geographic data needs special care</strong> - Spatial correlations are complex and critical</li> </ol> <p>Have you worked with synthetic data generation? What approaches have worked (or failed) for you? I’d love to hear about your experiences!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" target="_blank" rel="external nofollow noopener">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2" target="_blank" rel="external nofollow noopener">Displaying External Posts on Your al-folio Blog</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/llm-insights-engine/">Building an LLM-Powered Insights Engine That Doesn't Hallucinate</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mongodb-postgresql-ml/">From MongoDB to PostgreSQL: Database Architecture for ML Projects</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/plotly/">a post with plotly.js</a> </li> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Pinco Pallino. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>, forked from <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: October 24, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>