<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Building an LLM-Powered Insights Engine That Doesn't Hallucinate | Pinco Pallino </title> <meta name="author" content="Pinco Pallino"> <meta name="description" content="How I redesigned our audience insights system using LLMs while solving the hallucination problem for client-facing work"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A8%F0%9F%8F%BB%E2%80%8D%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://unique-cocada-065d88.netlify.app//blog/2025/llm-insights-engine/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Pinco</span> Pallino </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Building an LLM-Powered Insights Engine That Doesn't Hallucinate</h1> <p class="post-meta"> Created on October 24, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> LLM</a>   <a href="/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> machine-learning</a>   <a href="/blog/tag/data-engineering"> <i class="fa-solid fa-hashtag fa-sm"></i> data-engineering</a>   ·   <a href="/blog/category/data-science"> <i class="fa-solid fa-tag fa-sm"></i> data-science</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="the-problem-insights-buried-in-data-silos">The Problem: Insights Buried in Data Silos</h2> <p>When I joined my current company as a Senior Data Scientist, our audience insights process looked like this:</p> <ol> <li>An analyst receives a client request for audience insights</li> <li>They manually query <strong>one data source</strong> (maybe attitudinal surveys, maybe behavioral data)</li> <li>They create charts and write commentary in PowerPoint</li> <li>Repeat for each additional data source the client wants</li> <li>Deliver report weeks later</li> </ol> <p><strong>The issues were obvious:</strong></p> <ul> <li> <strong>Time-consuming</strong>: Each report took days or weeks of manual work</li> <li> <strong>Single-source bias</strong>: Using one data source at a time meant missing the full picture</li> <li> <strong>Not scalable</strong>: Each new client request started from scratch</li> <li> <strong>Limited interactivity</strong>: Clients couldn’t ask follow-up questions without another round of analysis</li> </ul> <p>The data was all there—attitudinal surveys, brand perception studies, behavioral data, location data—but it lived in separate silos. And even when analysts combined sources, the sheer volume made it overwhelming to navigate and extract meaningful insights.</p> <p><strong>What we needed:</strong> A system that could integrate multiple data sources and help users discover insights without requiring a data scientist for every question.</p> <p><strong>The natural solution in 2025:</strong> Large Language Models.</p> <hr> <h2 id="the-vision-multi-source-insights-on-demand">The Vision: Multi-Source Insights on Demand</h2> <p>I proposed building a system that would:</p> <ol> <li> <strong>Integrate multiple data sources</strong> into a unified view</li> <li> <strong>Use LLMs</strong> to automatically generate insights from the combined data</li> <li> <strong>Provide an interactive chat interface</strong> where users could ask questions naturally</li> <li> <strong>Deliver accurate, reliable answers</strong> suitable for client-facing work</li> </ol> <p>The last point was critical. This wasn’t an internal tool where “mostly right” would be acceptable. These insights would go directly to paying clients. <strong>Hallucinations were a dealbreaker.</strong></p> <hr> <h2 id="the-challenge-llms-hallucinate-a-lot">The Challenge: LLMs Hallucinate (A Lot)</h2> <p>If you’ve worked with LLMs, you know the problem: they’re <em>incredibly</em> good at generating plausible-sounding text, even when it’s completely wrong.</p> <p>Ask an LLM about your data, and you might get:</p> <ul> <li>Statistics that don’t exist in your dataset</li> <li>Trends that are pure invention</li> <li>Confident assertions based on nothing</li> </ul> <p>For internal exploration, you can fact-check. For client deliverables, <strong>you need zero tolerance for hallucination.</strong></p> <h3 id="why-standard-rag-wasnt-enough">Why Standard RAG Wasn’t Enough</h3> <p>The standard approach for grounding LLMs is Retrieval-Augmented Generation (RAG): retrieve relevant context, pass it to the LLM, generate response. But in my case:</p> <ul> <li> <strong>Problem 1</strong>: [Describe specific limitation of RAG for your use case]</li> <li> <strong>Problem 2</strong>: [Another challenge you faced]</li> <li> <strong>Problem 3</strong>: [Why it wasn’t sufficient for your data]</li> </ul> <p>I needed something more robust.</p> <hr> <h2 id="the-solution-your-anti-hallucination-approach">The Solution: [Your Anti-Hallucination Approach]</h2> <p>After experimenting with several approaches, I developed a system that <strong>essentially eliminates hallucinations</strong> through [describe your key innovation].</p> <h3 id="the-key-insight">The Key Insight</h3> <p>[Explain the conceptual breakthrough that made your solution work. What did you realize about the problem that led to your approach?]</p> <h3 id="technical-implementation">Technical Implementation</h3> <p><strong>Architecture Overview:</strong></p> <p>The system has [X] main components:</p> <ol> <li> <strong>Data Integration Layer</strong> <ul> <li>[How you unified the different data sources]</li> <li>[What transformations or standardizations were needed]</li> <li>[Technologies used: databases, APIs, etc.]</li> </ul> </li> <li> <strong>Query Processing</strong> <ul> <li>[How you parse user questions]</li> <li>[How you determine what data is relevant]</li> <li>[Any NLP preprocessing steps]</li> </ul> </li> <li> <strong>LLM Orchestration</strong> <ul> <li> <strong>Model used</strong>: [Which LLM? OpenAI, Anthropic, open-source?]</li> <li> <strong>Prompting strategy</strong>: [How you structured prompts]</li> <li> <strong>Temperature settings</strong>: [What temperature/sampling you used]</li> </ul> </li> <li> <strong>Hallucination Prevention</strong> <ul> <li>[Your specific technique - this is the most important part!]</li> <li>[How you verify LLM outputs against actual data]</li> <li>[Any validation or checking mechanisms]</li> </ul> </li> <li> <strong>Response Generation</strong> <ul> <li>[How you format final outputs]</li> <li>[Any post-processing steps]</li> </ul> </li> </ol> <h3 id="why-this-works">Why This Works</h3> <p>[Explain why your approach prevents hallucinations. What’s the mechanism that ensures accuracy?]</p> <p><strong>Example workflow:</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>User asks: "What are the top interests of our audience in the 25-34 age group?"

System does:
1. [Step 1 of your process]
2. [Step 2]
3. [Step 3]
4. [Final validation step that ensures accuracy]

Output: [Example of what the system returns]
</code></pre></div></div> <hr> <h2 id="implementation-why-streamlit-not-tableau">Implementation: Why Streamlit (Not Tableau)</h2> <p>For the interface, I chose <strong>Streamlit</strong> over traditional BI tools like Tableau because:</p> <ol> <li> <strong>Custom LLM integration</strong>: [Why Tableau couldn’t handle your LLM needs]</li> <li> <strong>Interactive chat interface</strong>: [What you needed that BI tools don’t provide]</li> <li> <strong>[Other reason]</strong>: [Explain]</li> </ol> <h3 id="the-tech-stack">The Tech Stack</h3> <ul> <li> <strong>Frontend</strong>: Streamlit</li> <li> <strong>Backend</strong>: [Python? FastAPI? Other?]</li> <li> <strong>LLM Integration</strong>: [How you connected to the LLM - API, local model?]</li> <li> <strong>Data Storage</strong>: [Where the data lives - databases, data warehouse?]</li> <li> <strong>Data Sources</strong>: <ul> <li>Attitudinal surveys</li> <li>Brand perception data</li> <li>Behavioral data</li> <li>Location data</li> <li>[Any others?]</li> </ul> </li> </ul> <h3 id="user-experience">User Experience</h3> <p>The interface is deliberately simple:</p> <ol> <li> <strong>Data source selector</strong>: Users choose which datasets to include</li> <li> <strong>Chat interface</strong>: Natural language questions</li> <li> <strong>Insight display</strong>: [How you present results - charts, tables, text?]</li> <li> <strong>[Other features]</strong>: [Anything else worth highlighting?]</li> </ol> <hr> <h2 id="the-results-client-feedback">The Results: Client Feedback</h2> <p>When we demoed the system to potential clients, the feedback was <strong>overwhelmingly enthusiastic</strong>.</p> <p><strong>What resonated most:</strong></p> <ul> <li> <strong>Speed</strong>: Insights that used to take days now available instantly</li> <li> <strong>Depth</strong>: Multi-source integration revealed patterns that single-source analysis missed</li> <li> <strong>Interactivity</strong>: Clients could explore their data conversationally</li> <li> <strong>Trust</strong>: [How did you demonstrate the accuracy? What built their confidence?]</li> </ul> <h3 id="quantitative-impact">Quantitative Impact</h3> <p>Compared to the old manual process:</p> <ul> <li> <strong>Time savings</strong>: [X hours/days saved per report?]</li> <li> <strong>Data coverage</strong>: [X data sources vs 1 before?]</li> <li> <strong>Client satisfaction</strong>: [Any NPS scores or feedback metrics?]</li> <li> <strong>Business impact</strong>: [New deals closed? Existing clients expanded usage?]</li> </ul> <hr> <h2 id="lessons-learned">Lessons Learned</h2> <h3 id="1-hallucination-prevention-is-non-negotiable-for-production">1. Hallucination Prevention is Non-Negotiable for Production</h3> <p>You can’t just hope the LLM gets it right. You need <strong>systematic verification</strong> at every step.</p> <p>[Expand on this based on your experience]</p> <h3 id="2-second-major-lesson">2. [Second Major Lesson]</h3> <p>[What else did you learn? About LLMs, about your data, about user needs?]</p> <h3 id="3-third-major-lesson">3. [Third Major Lesson]</h3> <p>[Another key takeaway from the project]</p> <h3 id="4-the-right-tool-for-the-job">4. The Right Tool for the Job</h3> <p>Sometimes the “obvious” tool (Tableau for BI) isn’t the right choice when you’re doing something novel. Don’t be afraid to pick the technology that actually fits your requirements.</p> <hr> <h2 id="whats-next">What’s Next</h2> <p>The system is currently [in production / in pilot / being expanded / other status]. Next steps include:</p> <ul> <li>[Future enhancement 1]</li> <li>[Future enhancement 2]</li> <li>[Future enhancement 3]</li> </ul> <hr> <h2 id="technical-deep-dive-specific-component">Technical Deep Dive: [Specific Component]</h2> <details> <summary><strong>Click to expand: [Topic]</strong></summary> [Detailed technical explanation of a specific component, algorithm, or technique] </details> <hr> <h2 id="key-takeaways">Key Takeaways</h2> <p>For anyone building LLM-powered analytics tools:</p> <ol> <li> <strong>Hallucination prevention must be built into the architecture</strong>, not bolted on later</li> <li> <strong>Multi-source data integration is powerful</strong> but requires careful schema design</li> <li> <strong>User trust is earned through transparency</strong> - [how did you build trust?]</li> <li><strong>[Your fourth takeaway]</strong></li> </ol> <p>The opportunity with LLMs isn’t to replace human analysts—it’s to <strong>amplify their capabilities</strong> and make insights accessible to more people. But only if you can guarantee accuracy.</p> <hr> <h2 id="technologies-used">Technologies Used</h2> <table> <thead> <tr> <th><strong>Category</strong></th> <th><strong>Technology</strong></th> </tr> </thead> <tbody> <tr> <td>LLM</td> <td>[Model name]</td> </tr> <tr> <td>Frontend</td> <td>Streamlit</td> </tr> <tr> <td>Backend</td> <td>[Your stack]</td> </tr> <tr> <td>Data Integration</td> <td>[Tools/DBs used]</td> </tr> <tr> <td>Data Storage</td> <td>[Databases]</td> </tr> <tr> <td>Deployment</td> <td>[How/where deployed]</td> </tr> </tbody> </table> <hr> <h2 id="related-posts">Related Posts</h2> <ul> <li>[Future post on synthetic data for real estate]</li> <li>[Future post on GAN debugging]</li> </ul> <hr> <p><strong>Questions or comments?</strong> I’d love to hear from other data scientists working on production LLM systems. What approaches have you found effective for hallucination prevention?</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" target="_blank" rel="external nofollow noopener">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2" target="_blank" rel="external nofollow noopener">Displaying External Posts on Your al-folio Blog</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mongodb-postgresql-ml/">From MongoDB to PostgreSQL: Database Architecture for ML Projects</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/synthetic-data-ctgan/">Why I Built a Custom Synthetic Data Algorithm Instead of Using CTGAN</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/simple-cnn-wins/">When Simpler Models Win: Comparing 7 CNN Architectures</a> </li> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Pinco Pallino. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>, forked from <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: October 24, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>